{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn.model_selection as sk\n",
    "import mectools.data as dt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plotter(backend='Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "seed = 2384923\n",
    "samp = 0.01\n",
    "BATCH_SIZE = 32\n",
    "size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random init\n",
    "state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def load_path(tag, base='../tiles/density', ext='jpg'):\n",
    "    tag = f'{tag:07d}'\n",
    "    sub = tag[:4]\n",
    "    return f'{base}/{size}px/{sub}/{tag}.{ext}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "def eval_model(y, yhat, ymin=-2, ymax=2, nbins=10):\n",
    "    fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "\n",
    "    res = pd.DataFrame({'y': y, 'yhat': yhat}).astype(np.float)\n",
    "    res['err'] = res['yhat'] - res['y']\n",
    "    res1 = res.query(f'y > {ymin} and y < {ymax} and yhat > {ymin} and yhat < {ymax}')\n",
    "    ax0.hexbin(res1['y'], res1['yhat'], cmap=mpl.cm.Blues, gridsize=20);\n",
    "    \n",
    "    bins = np.linspace(ymin, ymax, nbins)\n",
    "    res['ybin'] = np.digitize(res['y'], bins)\n",
    "    res['ybin'] = np.minimum(nbins-1, res['ybin'])\n",
    "    bmean = res.groupby('ybin')['yhat'].mean()\n",
    "    bmean.plot(ax=ax1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in firm and location data\n",
    "firms = pd.read_csv('../firms/census_2004_geocode.csv', usecols=['id', 'industry', 'income', 'total_assets', 'employees'])\n",
    "targ = pd.read_csv('../targets/census_firms_2004.csv', usecols=['id', 'lat_wgs84', 'lon_wgs84'])\n",
    "firms = pd.merge(firms, targ, on='id', how='left').dropna()\n",
    "\n",
    "# downsample for now\n",
    "firms = firms.sample(frac=samp)\n",
    "\n",
    "# resolve image paths\n",
    "firms['file'] = firms['id'].apply(load_path)\n",
    "firms['fexist'] = firms['file'].apply(os.path.exists)\n",
    "firms = firms[firms['fexist']]\n",
    "\n",
    "# calculate outcome stats\n",
    "firms['prod'] = firms['income']/firms['employees']\n",
    "firms['lprod'] = dt.log(firms['prod'])\n",
    "firms = firms.dropna(subset=['lprod'])\n",
    "\n",
    "# calculate residual performance\n",
    "reg_ind = smf.ols('lprod ~ 0 + C(industry)', data=firms).fit()\n",
    "firms['lprod_resid'] = reg_ind.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in image features\n",
    "features = np.stack([np.array(PIL.Image.open(fn)) for fn in firms['file']])\n",
    "features = features[:,:,:,None].astype(np.float32)/255 # single channel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct outcome variable\n",
    "labels = firms['lprod'].values\n",
    "# labels = firms['lprod_resid'].values\n",
    "labels = labels[:,None].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/test split\n",
    "X_train, X_valid, y_train, y_valid = sk.train_test_split(features, labels, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model (1024px)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=8),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model (256px)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=8),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=4, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=16),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train keras model\n",
    "history = model.fit(X_train, y_train, epochs=25, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid = model.predict(X_valid)\n",
    "eval_model(y_valid[:,0], yhat_valid[:,0], ymin=2, ymax=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model.predict(X_train)\n",
    "eval_model(y_train[:,0], yhat_train[:,0], ymin=2, ymax=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean = keras.Sequential([\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model_mean.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model_mean.fit(X_train, y_train, epochs=25, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid = model_mean.predict(X_valid)\n",
    "eval_model(y_valid[:,0], yhat_valid[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = model_mean.predict(X_train)\n",
    "eval_model(y_train[:,0], yhat_train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "firms['dense_1024'] = features.reshape((len(firms), -1)).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = smf.ols('lprod_resid ~ dense_1024', data=firms).fit()\n",
    "reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(firms['lprod_resid'], reg.predict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadialPooling2D(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        size0 = self.add_weight(name='size0', shape=(1,), initializer='uniform', trainable=True)\n",
    "        size = 128*keras.activations.sigmoid(size0)\n",
    "        _, span_x, span_y, _ = input_shape\n",
    "        zero_x, zero_y = int(span_x//2), int(span_y//2)\n",
    "        vals_x, vals_y = tf.cast(tf.range(span_x), tf.float32), tf.cast(tf.range(span_y), dtype=tf.float32)\n",
    "        grid_x, grid_y = tf.meshgrid(vals_x, vals_y)\n",
    "        radius = tf.sqrt((grid_x-zero_x)**2+(grid_y-zero_y)**2)\n",
    "        self.mask = keras.activations.sigmoid(-(radius-size)/10)[None,:,:,None]\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.reshape(tf.reduce_mean(tf.multiply(x, self.mask)), (-1, 1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsize = 256\n",
    "inputs = keras.layers.Input(shape=(imsize, imsize, 1))\n",
    "pool = keras.layers.Concatenate()([RadialPooling2D()(inputs) for _ in range(5)])\n",
    "outputs = keras.layers.Dense(1)(pool)\n",
    "model_radial = keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "model_radial.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model_radial.fit(X_train, y_train, epochs=25, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_valid = model_radial.predict(X_valid)\n",
    "print(pd.Series(yhat_valid[:,0]).describe())\n",
    "eval_model(y_valid[:,0], yhat_valid[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}