{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn.model_selection as sk\n",
    "import mectools.data as dt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = plotter(backend='Agg')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "seed = 2384923\n",
    "samp = 0.05\n",
    "BATCH_SIZE = 32\n",
    "size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random init\n",
    "state = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def load_path(tag, base='tiles/density', ext='jpg'):\n",
    "    tag = f'{tag:07d}'\n",
    "    sub = tag[:4]\n",
    "    return f'{base}/{size}px/{sub}/{tag}.{ext}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in firm and location data\n",
    "firms = pd.read_csv('firms/census_2004_geocode.csv', usecols=['id', 'industry', 'income', 'total_assets', 'employees'])\n",
    "targ = pd.read_csv('targets/census_firms_2004.csv', usecols=['id', 'lat_wgs84', 'lon_wgs84'])\n",
    "firms = pd.merge(firms, targ, on='id', how='left').dropna()\n",
    "\n",
    "# downsample for now\n",
    "firms = firms.sample(frac=samp)\n",
    "\n",
    "# resolve image paths\n",
    "firms['file'] = firms['id'].apply(load_path)\n",
    "firms['fexist'] = firms['file'].apply(os.path.exists)\n",
    "firms = firms[firms['fexist']]\n",
    "\n",
    "# calculate outcome stats\n",
    "firms['prod'] = firms['income']/firms['employees']\n",
    "firms['lprod'] = dt.log(firms['prod'])\n",
    "firms = firms.dropna(subset=['lprod'])\n",
    "\n",
    "# calculate residual performance\n",
    "reg_ind = smf.ols('lprod ~ 0 + C(industry)', data=firms).fit()\n",
    "firms['lprod_resid'] = reg_ind.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in image features\n",
    "features = np.stack([np.array(PIL.Image.open(fn)) for fn in firms['file']])\n",
    "features = features[:,:,:,None].astype(np.float32)/255 # single channel image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct outcome variable\n",
    "# labels = firms['lprod_resid'].values\n",
    "labels = firms['lprod_resid'].values\n",
    "labels = labels[:,None].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/test split\n",
    "X_train, X_valid, y_train, y_valid = sk.train_test_split(features, labels, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model (1024px)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=8),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model (256px)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=8, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=8),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=4, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=4),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=32, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=16),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train keras model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "yhat_valid = model.predict(X_valid)\n",
    "res_valid = pd.DataFrame({'y': y_valid[:,0], 'yhat': yhat_valid[:,0]}).astype(np.float)\n",
    "res_valid['err'] = res_valid['yhat'] - res_valid['y']\n",
    "res_valid1 = res_valid.query('y > -2 and y < 2 and yhat > -2 and yhat < 2')\n",
    "sns.jointplot('y', 'yhat', data=res_valid1, kind='hex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate fit\n",
    "yhat_train = model.predict(X_train)\n",
    "res_train = pd.DataFrame({'y': y_train[:,0], 'yhat': yhat_train[:,0]}).astype(np.float)\n",
    "res_train['err'] = res_train['yhat'] - res_train['y']\n",
    "res_train1 = res_train.query('y > -2 and y < 2 and yhat > -2 and yhat < 2')\n",
    "sns.jointplot('y', 'yhat', data=res_train1, kind='hex');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "bins = np.linspace(-2, 2, nbins)\n",
    "res_valid['ybin'] = np.digitize(res_valid['y'], bins)\n",
    "res_valid['ybin'] = np.minimum(nbins-1, res_valid['ybin'])\n",
    "bmean = res_valid.groupby('ybin')['yhat'].mean()\n",
    "bmean.index = bins\n",
    "bmean.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "bins = np.linspace(-2, 2, nbins)\n",
    "res_train['ybin'] = np.digitize(res_train['y'], bins)\n",
    "res_train['ybin'] = np.minimum(nbins-1, res_train['ybin'])\n",
    "bmean = res_train.groupby('ybin')['yhat'].mean()\n",
    "bmean.index = bins\n",
    "bmean.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cx_train, cy_train), (cx_test, cy_test) = cifar10.load_data()\n",
    "cy_train = keras.utils.to_categorical(cy_train, 10)\n",
    "cy_test = keras.utils.to_categorical(cy_test, 10)\n",
    "cx_train = cx_train.astype('float32')/255\n",
    "cx_test = cx_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR like model\n",
    "cifar = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "chist = cifar.fit(cx_train, cy_train, batch_size=BATCH_SIZE, epochs=10, validation_data=(cx_test, cy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_input = np.random.randn(10000)[:,None]\n",
    "t_output = 1 + 2*t_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_train, tX_valid, ty_train, ty_valid = sk.train_test_split(t_input, t_output, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "model = keras.Sequential([keras.layers.Dense(units=1)])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "history = model.fit(tX_train, ty_train, epochs=20, validation_data=[tX_valid, ty_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "tyhat_valid = model.predict(tX_valid)\n",
    "tres = pd.DataFrame({'y': ty_valid[:,0], 'yhat': tyhat_valid[:,0]})\n",
    "tres['err'] = tres['yhat'] - tres['y']\n",
    "tres.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot('y', 'yhat', data=tres, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}